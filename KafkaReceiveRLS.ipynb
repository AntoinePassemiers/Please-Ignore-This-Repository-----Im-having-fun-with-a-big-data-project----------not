{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Least Square with Kafka and Spark streaming \n",
    "\n",
    "This notebook demonstrates how to implement a distributed algorithm for estimating the coefficients\n",
    "of multiple linear models on streaming data retrieved from a Kafka producer.\n",
    "Inference is achieved using the Recursive Least Squares (RLS) algorithm, by running many\n",
    "models in parallel with different forgetting factors.\n",
    "\n",
    "Massive parallelism enables rapid validation of the optimal value for the only hyper-parameter\n",
    "of the model, namely the forgetting factor.\n",
    "The algorithm is scalable both w.r.t. to the number of explained variables and the number of\n",
    "models run in parallel. Let's note that running multiple models in parallel and fitting\n",
    "linear models on different output variables are both embarassingly parallel tasks.\n",
    "\n",
    "Let $B \\in \\mathbb{R}^{n \\times m}$ be the coefficients to be learnt, $x_t \\in \\mathbb{R}^n$ the input sample\n",
    "of dimensionality $n$ retrieved at step $t$, $w \\in \\mathcal{N}(0, 1)$ some Gaussian noise\n",
    "and $y \\in \\mathbb{R}^m$ the $m$ output variables to be predicted.\n",
    "The linear regression fitted by the RLS algorithm can be formally described as such:\n",
    "\n",
    "$$\n",
    "y = x^T B + w\n",
    "$$\n",
    "\n",
    "However, such vectorized description of the model is not scalable and should be split\n",
    "w.r.t. to the explained variable, in such a way that each machine in the cluster computes\n",
    "the coefficients associated to a single explained variable $y_j$:\n",
    "\n",
    "$$\n",
    "y_j = x^T B_{\\cdot j} + w\n",
    "$$\n",
    "\n",
    "Where $B_{\\cdot j}$ is the jth column of matrix $B$. Actually, this notebook provides both implementations and \n",
    "privileges the vectorized one for small systems, for which the NumPy implementation of the dot-product\n",
    "has a competitive advantage over Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General import\n",
    "\n",
    "Let's import the general-purpose libraries and Spark modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "import time\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) RLS algorithm state representation - Vectorized approach\n",
    "\n",
    "Rather than implementing arbitrary object classes (which Spark can not handle in a stable manner),\n",
    "let's represent the current state of RLS algorithm execution with tuples.\n",
    "More formally, let's denote current state as a 7-uple of the following form:\n",
    "\n",
    "$$\n",
    "(k, B^{(t)}, V^{(t)}, \\nu, sse, t, \\text{None})\n",
    "$$\n",
    "\n",
    "where $k$ is a string representing the identifier of current model, $B^{(t)} \\in \\mathbb{R}^{n \\times m}$ is\n",
    "the coefficient matrix at time $t$, $V^{(t)}$ is matrix $V \\in \\mathbb{R}^{n \\times n}$ at time $t$,\n",
    "$\\nu$ is the forgetting factor of current model, $sse$ is the average square error of all predicted samples until step $t$,\n",
    "and the last element is the index of the explained variable to be fitted.\n",
    "In the vectorized implementation, all explained variables are fitted and the last element is thus set to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state(key, n, m, nu):\n",
    "    \"\"\"Creates a new RLS state.\n",
    "    \n",
    "    Parameters:\n",
    "        key (str): Identifier of current model.\n",
    "        n (int): Number of input/explicative variables.\n",
    "        m (int): Number of output/explained variables.\n",
    "        nu (float): Forgetting factor of current model.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: RLS state at the beginning of the algorithm's execution.\n",
    "    \"\"\"\n",
    "    Beta = np.squeeze(np.zeros((n, m)))\n",
    "    return (key, Beta, np.eye(n), nu, 0., 0., None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "States are being updated by Spark by repeated calls to a function which has to\n",
    "be defined beforehand. Such function should be able to handle multiple\n",
    "input examples (sample size greater than one) at once. Therefore, let's define\n",
    "a decorator for the automatically adapts the update function by calling the later\n",
    "one time per input example. Such decorator is useful since it can be reused for\n",
    "the parallel implementation as well.\n",
    "\n",
    "Note: vectorized approach **is still scalable with respect to the number of models**.\n",
    "Models are thus always run in parallel,\n",
    "regardless of the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic(func):\n",
    "    \"\"\"Decorator for state update functions.\n",
    "    \n",
    "    Iteratively calls the update function for each\n",
    "    input example received from Kafka.\n",
    "    \n",
    "    Parameters:\n",
    "        func (callable): State update function.\n",
    "    \n",
    "    Returns:\n",
    "        callable: A new state update function.\n",
    "    \"\"\"\n",
    "    def new_func(new_values, state):\n",
    "        if len(new_values) > 0:\n",
    "            # Call the update function on each example,\n",
    "            # in the order in which they have been received.\n",
    "            for i in range(len(new_values)):\n",
    "                # Update current state\n",
    "                new_state = func(new_values[i], state)\n",
    "                state = new_state\n",
    "            return new_state\n",
    "        else:\n",
    "            return state\n",
    "    new_func.__name__ = func.__name__ # Preserve the name\n",
    "    return new_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement the actual state update function that will perform one step of the RLS algorithm.\n",
    "Let $V \\in \\mathbb{R}^{n \\times n}$ be a matrix that is required to be keft up-to-date at each\n",
    "step of the algorithm in order to compute $\\alpha \\in \\mathbb{R}^n$, a vector representing the lengths\n",
    "of the steps performed in the parameter space.\n",
    "Let $x_t \\in \\mathbb{R}^n$ be the vector of input variables observed at time $t$ and $y^{(t)}$ the corresponding\n",
    "vector of output variables at time $t$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{cases}\n",
    "    V^{(t)} & = \\frac{1}{\\nu} \\Bigg( V^{(t-1)} - \\frac{V^{(t-1)} x_t^T x_t V^{(t-1)}}{1 + x_t V^{(t-1)} (x_t^T} \\Bigg) \\\\\n",
    "    \\alpha_t & = V^{(t)} x_t^T \\\\\n",
    "    e^{(t)} & = y^{(t)} - x_t \\hat{B}^{(t-1)} \\\\\n",
    "    \\hat{B}^{(t)} & = \\hat{B}^{(t-1)} + \\alpha_t^T e^{(t)}\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$e^{(t)}$ are the errors given current model parameters on the example $(x_t, y^{(t)})$,\n",
    "and $e^{(t)}_i$ is the error on variable $y_i$ specifically. Given the current state:\n",
    "\n",
    "$$\n",
    "\\big(k, B^{(t)}, V^{(t)}, \\nu, sse^{(t)}, t, \\text{None}\\big)\n",
    "$$\n",
    "\n",
    "the update function computes the next step as:\n",
    "\n",
    "$$\n",
    "\\big(k, B^{(t+1)}, V^{(t+1)}, \\nu, sse^{(t+1)}, t+1, \\text{None})\n",
    "$$\n",
    "\n",
    "where $sse^{(t+1)} = \\frac{(t \\cdot sse^{(t)} + e^{(t+1)})}{t + 1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "@stochastic\n",
    "def full_state_update(new_example, state):\n",
    "    \"\"\"Perform one RLS step and return the new state.\n",
    "    \n",
    "    Parameters:\n",
    "        new_example (tuple): Tuple containing the model\n",
    "            identifier and the input example itself.\n",
    "            Input example is a NumPy array\n",
    "            of size (1 + m + n), where the first element\n",
    "            is the example identifier, the m next elements\n",
    "            are the values of output variables and the n last\n",
    "            elements are the values of input variables.\n",
    "        state (tuple): Current state of the algorithm.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: New state after performing one RLS step.\n",
    "    \"\"\"\n",
    "    yx = new_example[1] # Input example\n",
    "    key, Beta, V, nu, sse, N, _ = state # Unpack state\n",
    "    n_inputs, n_outputs = Beta.shape\n",
    "    \n",
    "    # i is the example identifier, y the output variables\n",
    "    # and x the input variables\n",
    "    i, y, x = yx[0], yx[1:n_outputs+1], yx[n_outputs+1:]\n",
    "\n",
    "    # Compute error\n",
    "    err = y - np.dot(x, Beta)\n",
    "    sse = (N * sse + np.mean(err ** 2.)) / (N + 1)\n",
    "\n",
    "    # Update V matrix\n",
    "    xtx = np.outer(x, x)\n",
    "    V = (V - (np.dot(V, np.dot(xtx, V))) / (1. + np.dot(x, np.dot(V, x)))) / nu\n",
    "\n",
    "    # Update coefficients\n",
    "    alpha = np.dot(V, x)\n",
    "    new_Beta = Beta + np.outer(alpha, err)\n",
    "    return (key, new_Beta, V, nu, sse, N + 1, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) RLS algorithm state representation - Parallel approach\n",
    "\n",
    "In the parallel approach, the RLS agorithm is scalable not only w.r.t. to the number of models,\n",
    "**but also w.r.t. the number of output variables**. Therefore, RLS states should be redefined in such a way that\n",
    "only necessary coefficients are represented:\n",
    "\n",
    "$$\n",
    "(k, B_{\\cdot j}^{(t)}, V^{(t)}, \\nu, sse, t, j)\n",
    "$$\n",
    "\n",
    "$B_{\\cdot j}$ is the jth column of matrix $B$ and $j$ is the index of the explained variable to be fitted.\n",
    "It must be noted that the model is split into $m$ parts and matrix $V$ is computed for each varaible $y_j$:\n",
    "each node of the cluster can thus compute matrix $V$ itself instead of waiting for another machine to do it.\n",
    "\n",
    "First, a function for splitting a state into multiple partial states should be defined.\n",
    "Each partial state contains a single column of the coefficient matrix $B$.\n",
    "It should be highlighted that such function is **called only once** per model before starting\n",
    "streaming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_state(state):\n",
    "    \"\"\"Splits a full state into multiple partial states.\n",
    "    \n",
    "    Each partial state is associated to a single output variable\n",
    "    and shares the same key with the original (full) state.\n",
    "    \n",
    "    Parameters:\n",
    "        state (tuple): Full state.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of `m` tuples (states) where each is associated\n",
    "            to a different output variables.\n",
    "    \"\"\"\n",
    "    m = state[1].shape[1]\n",
    "    partial_states = list()\n",
    "    for j in range(m):\n",
    "        key = state[0]\n",
    "        beta = state[1][:, j] # jth column of Beta\n",
    "        V, nu, sse, N, _ = state[2:]\n",
    "        new_state = (key, beta, np.copy(V), nu, sse, N, j)\n",
    "        partial_states.append(new_state)\n",
    "    return partial_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to retrieve the coefficients of the whole matrix $B$ as well as the error across all output variables,\n",
    "another function has to be defined. Such function necessarily needs to be run in parallel w.r.t. the number of models.\n",
    "For each model, the partial states are concatenated in order to obtain the full state, where the later is of the same\n",
    "form as the states used in the vectorized approach.\n",
    "\n",
    "The implementation is quite simple, as $k, V, \\nu, t$ are assumed to be equal across all partial states of a same model.\n",
    "The only operation to be performed is initializing the values of $B_{\\cdot j}$ with the vector of partial state $j$,\n",
    "for each partial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_partial_states(states):\n",
    "    \"\"\"Combines partial states of a same model into a single state.\n",
    "    \n",
    "    Parameters:\n",
    "        states (list): List of tuples where each tuple is\n",
    "            a partial state.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Full state.\n",
    "    \"\"\"\n",
    "    # All the following info is retrieved from\n",
    "    # the first state of the list but is supposed\n",
    "    # to be the same everywhere\n",
    "    n_inputs = len(states[0][1])\n",
    "    n_outputs = len(states)\n",
    "    key = states[0][0]\n",
    "    V = states[0][2]\n",
    "    nu = states[0][3]\n",
    "    N = states[0][5]\n",
    "    \n",
    "    # Errors will be averaged across partial states.\n",
    "    sses = list()\n",
    "    \n",
    "    # Initialize Beta column by column\n",
    "    Beta = np.zeros((n_inputs, n_outputs))\n",
    "    for state in states:\n",
    "        j = state[6] # Index of the output variable\n",
    "        Beta[:, j] = state[1]\n",
    "        sses.append(state[4])\n",
    "    sse = np.mean(sses)\n",
    "    return (key, Beta, V, nu, sse, N, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each RLS step is performed slightly differently than in the vectorized approach.\n",
    "Matrix $V^{(t)}$ is updated exactly the same way. However, only the jth column \n",
    "of coefficient matrix $B$ are updated, based on the error on variable $y_j$ solely.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{cases}\n",
    "    \\alpha_t & = V^{(t)} x_t^T \\\\\n",
    "    e^{(t)} & = y_j^{(t)} - x_t \\hat{B}_{\\cdot j}^{(t-1)} \\\\\n",
    "    \\hat{B}_{\\cdot j}^{(t)} & = \\hat{B}_{\\cdot j}^{(t-1)} + \\alpha_t^T e^{(t)}\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "    @stochastic\n",
    "    def partial_state_update(new_example, state):\n",
    "        yx = new_example[1]\n",
    "        key, beta, V, nu, sse, N, j = state\n",
    "        n_inputs = len(beta)\n",
    "        n_outputs = len(yx) - n_inputs - 1\n",
    "        i, y, x = yx[0], yx[j+1], yx[n_outputs+1:]\n",
    "\n",
    "        # Compute error\n",
    "        err = y - np.dot(x, beta)\n",
    "        sse = (N * sse + err ** 2.) / (N + 1)\n",
    "\n",
    "        # Update V matrix\n",
    "        xtx = np.outer(x, x)\n",
    "        V = (V - (np.dot(V, np.dot(xtx, V))) / (1. + np.dot(x, np.dot(V, x)))) / nu\n",
    "\n",
    "        # Update Beta matrix\n",
    "        alpha = np.dot(V, x)\n",
    "        new_beta = beta + alpha * err\n",
    "        return (key, new_beta, V, nu, sse, N + 1, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global constants - RLS\n",
    "\n",
    "The following constants are dedicated to the learning process itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of input/explanatory variables\n",
    "n = 10\n",
    "\n",
    "# Number of output/explained variables\n",
    "m = 8\n",
    "\n",
    "# Threshold for using the parallel approach.\n",
    "# When the number of output variables exceeds\n",
    "# this threshold, the parallel approach is used\n",
    "# instead of the vectorized one.\n",
    "tau_local = 6\n",
    "\n",
    "# Number of models to train in parallel\n",
    "# for future validation of `nu`\n",
    "n_models = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the state update functions\n",
    "\n",
    "Let's quickly test both implementations of the RLS update function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.asarray([0] + [1.] * (n + m))\n",
    "assert(full_state_update([('-', values)], create_state('-', n, m, 1.)))\n",
    "state = create_state('-', n, 1, 1.)\n",
    "assert(partial_state_update([('-', values)], split_state(create_state('-', n, m, 1.))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define streaming pipeline\n",
    "\n",
    "---\n",
    "\n",
    "In the figure below, both approaches are shown. Transformations in the vectorized approach are\n",
    "represented by plain lines and transformations in the distributed approach are represented by dashed lines.\n",
    "In both approaches, the DStream is first transformed using a map transformation, as indicated by transformation (1).\n",
    "Transformation (1) converts messages received from Kafka to key/value pairs where the key is the name of the model\n",
    "and the value is a NumPy array containing the numerical values present in the messages.\n",
    "\n",
    "Initial RLS states are obtained by running *create_state* function multiple times.\n",
    "A full state refers to a state related the whole coefficient matrix $B$ of a model,\n",
    "while a partial state is related to only a specific column of $B$.\n",
    "In the distributed approach, each initial state is split into $m$ partial states with transformation (3) beforehand.\n",
    "Note that all partial states share the same key as the original full state.\n",
    "These partial states are then updated using *partial_state_update* function as indicated by transformation (4).\n",
    "In the vectorized approach, the full states are updated using *full_state_update* function as indicated by transformation (2).\n",
    "\n",
    "In the distributed approach, full states are reconstructed with a groupByKey operation directly followed by a map operation.\n",
    "These two transformations are represented by the single transformation (5).\n",
    "Transformation (6) is a generic map transformation used for retrieving information and eventually displaying it,\n",
    "like the prediction error.\n",
    "\n",
    "<img src=\"report/imgs/lineage-graph.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Spark session and initialize DStream\n",
    "\n",
    "Let's initialize the Spark session as well as the DStream. It should be noted that everytime the stream is\n",
    "stopped, the notebook should be re-run from this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Global constants\n",
    "TOPIC = 'dataLinearModel'\n",
    "BATCH_INTERVAL = 1\n",
    "\n",
    "# Change command line Spark job submission arguments\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--conf spark.ui.port=4040 ' + \\\n",
    "                                '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.2.1 ' + \\\n",
    "                                '--conf spark.driver.memory=2g  pyspark-shell'\n",
    "\n",
    "# Initialize Spark session and retrieve context\n",
    "spark = SparkSession.builder.master('local[2]').appName('KafkaReceive').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Create streaming context, with required batch interval\n",
    "ssc = StreamingContext(sc, BATCH_INTERVAL)\n",
    "\n",
    "# Checkpointing needed for stateful transforms\n",
    "ssc.checkpoint('checkpoint')\n",
    "\n",
    "# Create a DStream that represents streaming data from Kafka, for the required topic\n",
    "dstream = KafkaUtils.createDirectStream(ssc, [TOPIC], {'metadata.broker.list': 'localhost:9092'})\n",
    "# IMPORTANT NOTE: The following line can be used as well, but may not succeed on Windows:\n",
    "# dstream = KafkaUtils.createStream(ssc, \"127.0.0.1:2181\", \"spark-streaming-consumer\", {topic: 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement the figure shown earlier, using Spark transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:53\n",
      "-------------------------------------------\n",
      "2.9571105748488653e+18\n",
      "0.11255325708866594\n",
      "0.12195607144943638\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:54\n",
      "-------------------------------------------\n",
      "2.977864176434359e+18\n",
      "0.11173382127664484\n",
      "0.12084296511047687\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:55\n",
      "-------------------------------------------\n",
      "3.8293294102546765e+18\n",
      "0.11132280967602787\n",
      "0.11985480402627552\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:56\n",
      "-------------------------------------------\n",
      "8.717901756521702e+18\n",
      "0.11051489446618638\n",
      "0.11881966279151067\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:57\n",
      "-------------------------------------------\n",
      "8.849555407686972e+18\n",
      "0.10989386982270696\n",
      "0.11783641997338698\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:58\n",
      "-------------------------------------------\n",
      "8.847413130981273e+18\n",
      "0.10928955413410063\n",
      "0.11691037904975161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating one initial state per model\n",
    "# Each model is assigned a different forgetting parameter\n",
    "nus = np.linspace(0.5, 1.0, n_models)\n",
    "initial_states = [create_state('mod%i' % (i + 1), n, m, nus[i]) for i in range(n_models)]\n",
    "\n",
    "# Evaluate inputs to lists and convert them to arrays\n",
    "array_dstream = dstream.map(lambda x: np.array(ast.literal_eval(x[1])))\n",
    "#dstream.pprint()\n",
    "\n",
    "array_dstream = array_dstream.flatMap(lambda x: [('mod%i' % (i + 1), ('mod%i' % (i + 1), x)) for i in range(n_models)])\n",
    "#dstream.pprint()\n",
    "\n",
    "full_state_RDD = sc.parallelize([(u'mod%i' % (i + 1), initial_states[i]) for i in range(n_models)])\n",
    "\n",
    "if m <= tau_local: # (1) Fully-vectorized approach\n",
    "    updated_full_state_dstream = array_dstream.updateStateByKey(full_state_update, initialRDD=full_state_RDD)\n",
    "else: # (2) Distributed approach\n",
    "    partial_state_RDD = full_state_RDD.flatMap(lambda x: [(x[0], s) for s in split_state(x[1])])\n",
    "    updated_partial_state_dstream = array_dstream.updateStateByKey(partial_state_update, initialRDD=partial_state_RDD)\n",
    "    updated_full_state_dstream = updated_partial_state_dstream.groupByKey().map(lambda x: (x[0], merge_partial_states(x[1])))\n",
    "#dstream.pprint()\n",
    "\n",
    "results = updated_full_state_dstream.map(lambda x: x[1][4])\n",
    "results.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start streaming application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:35\n",
      "-------------------------------------------\n",
      "120567587675218.4\n",
      "0.12516961962001938\n",
      "0.14428107706797005\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:36\n",
      "-------------------------------------------\n",
      "121637476180234.19\n",
      "0.12391704176031752\n",
      "0.14273099238372378\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:37\n",
      "-------------------------------------------\n",
      "135509618075264.62\n",
      "0.1232290774025106\n",
      "0.14116484014243094\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:38\n",
      "-------------------------------------------\n",
      "195898241482433.9\n",
      "0.12234484424075599\n",
      "0.1397297009207737\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:39\n",
      "-------------------------------------------\n",
      "271795851317570.34\n",
      "0.1220659662001355\n",
      "0.1385530037138907\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:40\n",
      "-------------------------------------------\n",
      "6374228582818528.0\n",
      "0.12283934020318288\n",
      "0.13722609344573858\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:41\n",
      "-------------------------------------------\n",
      "1.199256196979507e+16\n",
      "0.12069193211866858\n",
      "0.13453048475044513\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:42\n",
      "-------------------------------------------\n",
      "1.199256196979507e+16\n",
      "0.12069193211866858\n",
      "0.13453048475044513\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:43\n",
      "-------------------------------------------\n",
      "2.34039869151903e+16\n",
      "0.12006496635532352\n",
      "0.13341746579206185\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:44\n",
      "-------------------------------------------\n",
      "2.8000250214039948e+16\n",
      "0.11898487854790042\n",
      "0.1320671575530666\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:45\n",
      "-------------------------------------------\n",
      "8.222982865585861e+16\n",
      "0.11784195125112629\n",
      "0.130796585187395\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:46\n",
      "-------------------------------------------\n",
      "1.4466228908210064e+17\n",
      "0.11686957701645836\n",
      "0.1295889913287737\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:47\n",
      "-------------------------------------------\n",
      "1.478935509711793e+17\n",
      "0.11612946220589496\n",
      "0.12849160105153654\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:48\n",
      "-------------------------------------------\n",
      "1.6163856505390154e+17\n",
      "0.11529828703756038\n",
      "0.12735450250512156\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2019-08-29 22:14:49\n",
      "-------------------------------------------\n",
      "2.755257565160151e+17\n",
      "0.1145044295708392\n",
      "0.12630479303254208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop(stopSparkContext=True, stopGraceFully=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
